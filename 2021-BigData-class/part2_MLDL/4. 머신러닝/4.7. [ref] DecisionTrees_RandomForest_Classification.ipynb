{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "DecisionTrees_RandomForest_Classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDjgunkrrwL7"
      },
      "source": [
        "# Random Forest applied to LendingClub data set \n",
        "\n",
        "For this exercise, we will be exploring publicly available data from [LendingClub.com](www.lendingclub.com). Lending Club connects people who need money (borrowers) with people who have money (investors). We try to create a model to predict the risk of lending money to someone given a wide range of credit related data. We will use lending data from 2007-2010 and be trying to classify and predict **whether or not the borrower paid back their loan in full.**\n",
        "\n",
        "Here are what the columns in the data set represent:\n",
        "\n",
        "* **credit.policy**: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
        "* **purpose**: The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n",
        "* **int.rate**: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n",
        "* **installment**: The monthly installments owed by the borrower if the loan is funded.\n",
        "* **log.annual.inc**: The natural log of the self-reported annual income of the borrower.\n",
        "* **dti**: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n",
        "* **fico**: The FICO credit score of the borrower.\n",
        "* **days.with.cr.line**: The number of days the borrower has had a credit line.\n",
        "* **revol.bal**: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n",
        "* **revol.util**: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n",
        "* **inq.last.6mths**: The borrower's number of inquiries by creditors in the last 6 months.\n",
        "* **delinq.2yrs**: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
        "* **pub.rec**: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).\n",
        "* **not.fully.paid**: The quantity of interest for classification - whether the borrower paid back the money in full or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8uyoRzFrwL_"
      },
      "source": [
        "# Import Libraries and data set\n",
        "\n",
        "**Import the usual libraries for pandas and plotting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBox8ldirwL_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tT4gGEarwMB"
      },
      "source": [
        "### Get the Data\n",
        "\n",
        "** Use pandas to read loan_data.csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsj8GnPBrwMB"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/hukim1112/MLDL/master/lecture3/loan_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp-RlCk7rwMB"
      },
      "source": [
        "### Check out the info(), head(), and describe() methods on loans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFGuqJq1rwMC"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90X20MSdrwMD"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCjsI9aDrwME"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6TlyL8krwMF"
      },
      "source": [
        "print(\"Follwoing is a breakup of credit approval status. 1 means approved credit, 0 means not approved.\")\n",
        "print(df['credit.policy'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukx7zYdHvmFv"
      },
      "source": [
        "### Scrub (filtering, extracting , replacing , handle missing values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu56ul5PvjIx"
      },
      "source": [
        "NAN_value = (df.isnull().sum() / len(df)) * 100\n",
        "Missing = NAN_value[NAN_value==0].index.sort_values(ascending=False)\n",
        "Missing_data = pd.DataFrame({'Missing Ratio' :NAN_value})\n",
        "Missing_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPyUCuNrwMF"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo7mfhJhrwMG"
      },
      "source": [
        "### Histogram of FICO scores by credit approval status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNdQZ6rHrwMG"
      },
      "source": [
        "df[df['credit.policy']==1]['fico'].plot.hist(bins=30,alpha=0.5,color='blue', label='Credit.Policy=1')\n",
        "df[df['credit.policy']==0]['fico'].plot.hist(bins=30,alpha=0.5, color='red', label='Credit.Policy=0')\n",
        "plt.legend(fontsize=15)\n",
        "plt.title (\"Histogram of FICO score by approved or disapproved credit policies\", fontsize=16)\n",
        "plt.xlabel(\"FICO score\", fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov9QoOyprwMG"
      },
      "source": [
        "### Presence or absence of statistical difference of various factors between credit approval status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fBF_493MrwMH"
      },
      "source": [
        "sns.boxplot(x=df['credit.policy'],y=df['int.rate'])\n",
        "plt.title(\"Interest rate varies between risky and non-risky borrowers\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Interest rate\",fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4eGKDt0rwMJ"
      },
      "source": [
        "sns.boxplot(x=df['credit.policy'],y=df['log.annual.inc'])\n",
        "plt.title(\"Income level does not make a big difference in credit approval odds\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Log. annual income\",fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FsLez6JrwMK"
      },
      "source": [
        "sns.boxplot(x=df['credit.policy'],y=df['days.with.cr.line'])\n",
        "plt.title(\"Credit-approved users have a slightly higher days with credit line\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Days with credit line\",fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn-brqKDrwML"
      },
      "source": [
        "sns.boxplot(x=df['credit.policy'],y=df['dti'])\n",
        "plt.title(\"Debt-to-income level does not make a big difference in credit approval odds\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Debt-to-income ratio\",fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAX8Noo2rwML"
      },
      "source": [
        "### Countplot of loans by purpose, with the color hue defined by not.fully.paid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TM5SsGCrwML"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='purpose',hue='not.fully.paid',data=df, palette='Set1')\n",
        "plt.title(\"Bar chart of loan purpose colored by not fully paid status\", fontsize=17)\n",
        "plt.xlabel(\"Purpose\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3F85owhrwMM"
      },
      "source": [
        "### Trend between FICO score and interest rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2oLaEzqrwMM"
      },
      "source": [
        "sns.jointplot(x='fico',y='int.rate',data=df, color='purple', size=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axHRd0DIrwMM"
      },
      "source": [
        "# Setting up the Data\n",
        "## Categorical Features\n",
        "\n",
        "The **purpose** column as categorical. We transform them using dummy variables so sklearn will be able to understand them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlYWEIdfrwMM"
      },
      "source": [
        "df_final = pd.get_dummies(df,['purpose'],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky3PO-ZarwMN"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kaO0hvWrwMN"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-EIvTfurwMN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df_final.drop('not.fully.paid',axis=1)\n",
        "y = df_final['not.fully.paid']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_qFZH9crwMN"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ablGhvrsrwMN"
      },
      "source": [
        "## Training a Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTUf3pMBrwMN"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcUPVepfrwMO"
      },
      "source": [
        "**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3dGa8jHrwMO"
      },
      "source": [
        "dtree = DecisionTreeClassifier(criterion='gini',max_depth=None, min_samples_leaf=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qj42iYUrwMO"
      },
      "source": [
        "dtree.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDyEJCE_tyd6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as ACC\n",
        "\n",
        "Y_pred = dtree.predict(X_test)\n",
        "acc = ACC(y_test, Y_pred)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2DNHdojtFI0"
      },
      "source": [
        "### Decision tree 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7WsXFCIsryU"
      },
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure( figsize = (30,20))\n",
        "plot_tree(dtree, feature_names = X_train.columns, \n",
        "          class_names = ['fully.paid', 'not.fully.paid'], fontsize=15,\n",
        "          proportion=False, \n",
        "          filled=True, rounded=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nGLYT6GtwXd"
      },
      "source": [
        "### feature importance 시각화\n",
        "\n",
        "세로축 : 특징 종류\n",
        "\n",
        "가로축 : 상대적 중요도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeeqfBlZtN1z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.barh(y = X_train.columns, width = dtree.feature_importances_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGJ5lLzurwMO"
      },
      "source": [
        "## Predictions and Evaluation of Decision Tree\n",
        "**Create predictions from the test set and create a classification report and a confusion matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XS3PoCrwMO"
      },
      "source": [
        "predictions = dtree.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YMeA2XkrwMO"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54aJI2x8rwMO"
      },
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n7vIFC9rwMP"
      },
      "source": [
        "cm=confusion_matrix(y_test,predictions)\n",
        "print(cm)\n",
        "print (\"Accuracy of prediction:\",round((cm[0,0]+cm[1,1])/cm.sum(),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJOXLbprwMP"
      },
      "source": [
        "## Training the Random Forest model\n",
        "\n",
        "Now its time to train our model!\n",
        "\n",
        "**Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBetGflurwMP"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uubmo_TrwMP"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHmeso8SrwMQ"
      },
      "source": [
        "rfc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bAMaHQarwMQ"
      },
      "source": [
        "## Predictions and Evaluation\n",
        "\n",
        "Let's predict off the y_test values and evaluate our model.\n",
        "\n",
        "** Predict the class of not.fully.paid for the X_test data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aewJyuw5rwMQ"
      },
      "source": [
        "rfc_pred = rfc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL39O4h6rwMQ"
      },
      "source": [
        "**Now create a classification report from the results. Do you get anything strange or some sort of warning?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTWXt128rwMQ"
      },
      "source": [
        "cr = classification_report(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlJq95WirwMQ"
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNL8YggcrwMR"
      },
      "source": [
        "**Show the Confusion Matrix for the predictions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5CH42jZrwMR"
      },
      "source": [
        "cm = confusion_matrix(y_test,rfc_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "NJ56nKfIrwMR"
      },
      "source": [
        "### Running a loop with increasing number of trees in the random forest and checking accuracy of confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zkJiPitrwMR"
      },
      "source": [
        "**Criterion 'gini' or 'entropy'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn4T2nzMrwMR"
      },
      "source": [
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH2vbDMyrwMR"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'gini')\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-wcxPWrrwMS"
      },
      "source": [
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='entropy')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S9xH3bCrwMS"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'entropy')\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LGYqrNHrwMS"
      },
      "source": [
        "**Fixing max tree depth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UcIklTPrwMS"
      },
      "source": [
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RXhJuQBrwMS"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: None)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY_YVvVnrwMS"
      },
      "source": [
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=5,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmGWKvu8rwMT"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: 5)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4z22R1ZrwMT"
      },
      "source": [
        "**Minimum sample split criteria**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL-VGfLzrwMT"
      },
      "source": [
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=2,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LG5toTNrwMT"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 2)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeK8SoEmrwMU"
      },
      "source": [
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=20,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9F4a8nRrwMU"
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 20)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqBQcyJ4rwMU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3u0X8dn0eX5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}